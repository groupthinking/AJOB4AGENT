# OpenAI Configuration
# Get your API key from https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here

# Model Configuration
# Options: gpt-4, gpt-4-turbo-preview, gpt-3.5-turbo
OPENAI_MODEL=gpt-4

# Maximum tokens for API responses
OPENAI_MAX_TOKENS=2000

# Temperature for response creativity (0.0-1.0)
# Lower = more deterministic, Higher = more creative
OPENAI_TEMPERATURE=0.7

# Service Configuration
LLM_SERVICE_PORT=8002
LOG_LEVEL=INFO

# CORS Settings (comma-separated)
ALLOWED_ORIGINS=http://localhost:3001,http://localhost:8080
ALLOWED_HOSTS=localhost,127.0.0.1,llm-service

# Rate Limiting
MAX_REQUESTS_PER_MINUTE=60

# Retry Configuration
MAX_RETRIES=3
RETRY_DELAY=1.0
